import re

# def extract(text):
#     if "æœ€ç»ˆå›å¤" in text:
#         response = text.split("æœ€ç»ˆå›å¤", 1)[-1].strip()  # ä½¿ç”¨ strip() å»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
#     else:
#         response = None  # å¦‚æœæ²¡æœ‰æ‰¾åˆ° "###Response"
#     return response

# text = """
# åˆ¶å®šå›å¤ç­–ç•¥

# è§£é‡Š[\boxed{}]çš„æ¥æºå’Œç”¨é€”ã€‚
# ç¡®è®¤å…¶åœ¨å¯¹è¯ä¸­çš„ä½œç”¨ï¼Œå¢å¼ºç”¨æˆ·ç†è§£ã€‚
# é¼“åŠ±ç”¨æˆ·ç»§ç»­æé—®ï¼Œä»¥æ»¡è¶³å…¶ä¿¡æ¯éœ€æ±‚ã€‚
# ç”Ÿæˆå›å¤å†…å®¹

# ä½¿ç”¨æ¸…æ™°çš„è¯­è¨€è§£é‡Š[\boxed{}]çš„å«ä¹‰ã€‚
# è¯´æ˜å…¶åœ¨å›å¤ä¸­çš„åº”ç”¨ç›®çš„ã€‚
# æä¾›è¿›ä¸€æ­¥çš„å¸®åŠ©å’Œæ”¯æŒã€‚
# æœ€ç»ˆå›å¤

# [\boxed{ä½ å¥½ğŸ‘‹ï¼æ¬¢è¿å†æ¬¡ä¸æˆ‘äº¤æµï¼å…³äºä½ æåˆ°çš„[\boxed{}]ï¼Œè¿™æ˜¯ä¸€ä¸ªæ•°å­¦å…¬å¼æ’ç‰ˆä¸­å¸¸ç”¨çš„æ ‡è®°ï¼Œç”¨äºå°†å†…å®¹æ¡†èµ·æ¥ï¼Œä½¿å…¶çªå‡ºæ˜¾ç¤ºã€‚åœ¨æˆ‘ä»¬çš„å¯¹è¯ä¸­ï¼Œæˆ‘ä½¿ç”¨[\boxed{}]æ¥å¼ºè°ƒæˆ‘çš„æœ€ç»ˆå›å¤ï¼Œä½¿å®ƒæ›´æ˜“äºè¯†åˆ«å’Œé˜…è¯»ã€‚å¸Œæœ›è¿™èƒ½å¸®åŠ©ä½ ç†è§£æˆ‘çš„å›å¤ç»“æ„ï¼æœ‰ä»€ä¹ˆå…¶ä»–é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥è§£é‡Šçš„åœ°æ–¹ï¼Œéšæ—¶å‘Šè¯‰æˆ‘å“¦ï¼}]
# """

# # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰ "boxed" æ ‡è®°å†…çš„å†…å®¹
# pattern = r'$\boxed\{(.*?)\}$'
# matches = re.findall(pattern, text, re.DOTALL)

# # è¾“å‡ºæ‰¾åˆ°çš„æ‰€æœ‰åŒ¹é…é¡¹
# for i, match in enumerate(matches):
#     print(f"åŒ¹é… {i+1}: {match.strip()}")

# print(extract(text))

import os
from dotenv import load_dotenv
from langchain_community.chat_models import ChatZhipuAI
import streamlit as st
from langchain.prompts import ChatPromptTemplate

# # åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
# load_dotenv(dotenv_path='ZHIPUAI_API_KEY.env', override=True)
# # è·å– API å¯†é’¥
# api_key = os.environ["ZHIPUAI_API_KEY"] 

# llm = ChatZhipuAI(
#     model="GLM-4-Air",
#     api_key=api_key,
#     temperature=0
# )

# res = llm.invoke("å†™ä¸€æ®µä½¿ç”¨pythonç”»å¿ƒå½¢çš„ä»£ç ")
# print(res)